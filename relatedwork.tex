\section{Related Work}
Our work builds on top of three major areas of prior work: \automl systems, human-centric view of \automl and user studies of data science practitioners. 

\subsection{Automated Machine Learning (\automl) Systems}
\par % state of automl
\automl technology is fast-growing and still in very much in its nascency, with a diverse set of commercial and academic offerings. Interfaces of \automl tools ranges from GUI-based to programmatic, catering to different groups of users, including machine learning engineers, data scientists, and non-programming business users. \automl tools vary in the degree of input customizability they offer, as well as their output model transparency. For example, some systems allow users to specify a range of models to select from (CITE) or metrics to optimize (CITE), while others (CITE) only allow users to specify the problem objective, such as classification or regression. In terms of the model output, some tools (CITE) exposes the model in its entirety to the user so that they can be fine-tuned further, while others (CITE google automl) simply return a monolithic black-box model that serves predictions. While \automl tools have traditionally focused on automating the modelling phase of in the machine learning lifecycle, there has been a growing suite of \automl tools that aims to democratize the end-to-end machine learning process, from data pre-processing to model building to post-processing. 
%These tools offers varying levels of support for all stages of the machine learning workflow, while others offer partial solution that only address one or two phases of the machine learning workflow. They also vary in their underlying optimization techniques, transparency and customizability. 
However, despite the excitement around this emerging technology, there have been little evaluation on how such tools are used in practice. In this paper, we sought to understand the adoption of \automl tools, their usage, and the current bottlenecks that users are facing with these tools.

% ---- community understanding 

% The intention of the tools is to relieve practitioners of the repetitive and time-consuming tasks in the machine learning process while providing solutions at speed and spare human resource time for other critical tasks that are not easily automated.


% Data pre-processing includes ETL, data cleaning, and exploratory data analysis. Model building involves model selection, hyperparameter tuning, and model ensembling. Post-processing include performance evaluation and insight and report generation. 

% (however, many practitioners enjoy the practices. refer to 203.)

% These tools largely fall into three categories based on their accessibility: open source packages such as \cite{Feurer:autosklearn,TPOT:Olson, auto-keras}, commercial services such as Amazon Sagemaker, Google AutoML, H2O Driveless AI, DataRobot and enterprise internal tools such as FBLearner. These tools can be categorized based on their comprehensiveness: some offer end-to-end solution with various levels of support for all stages of the machine learning workflow, while others offer partial solution that only address one or two phases of the machine learning workflow. They also vary in their underlying optimization techniques, transparency and customizability. The lack of control and opacity in many of these \automl tools have spurred interest in research around human-oriented \automl.

\subsection{Human-Centric \automl}
Some prior work has investigated the human-centric perspective of automated machine learning, advocating for a collaborative approach between human and automated machine learning \cite{Lee2019AHP,wang2018atmseer, gilHGML}, in which \automl augments human practitioners in speed and accuracy and human practitioners guide \automl using their domain knowledge. Taking a human-centric approach, these prior work explored data scientists' perceptions of  \automl, including concepts such as transparency, trust and interpretability and proposed design recommendations to increase human trust in \automl and the usability of tools through visual analytics \cite{wang2018atmseer, cashman et al snowcast}.   

Gil et al. proposed human-guided machine learning (HGML) as a hybrid approach to incorporate human knowledge to augment and improve the performance of \automl and argued that complete automation is not ideal for all use cases (Gil et al., 2019). In their study, Gil et al. analyzed machine learning workflows described in two academic publications from two different disciplines to complement their understanding of machine learning user behaviors and to inform their design recommendations for HGML systems.

% Snowcat \cite{Cashman et al., 2018} provides visualization of machine learning models used in \automl with the aim to shed light on the black boxes of \automl. Cashman et al. built the Snowcat system based on theoretical framework and architecture without using any qualitative methods. 

Wang et al. designed ATMSeer \cite{wang2018atmseer}, a visual analytics tool that enables search space refinement, computational budget adjustment, and model selection reasoning.  They designed ATMSeer based on feedback from semi-structured interviews with six machine learning practitioners in which they sought to understand the opportunities exist to improve the process of how machine learning practitioners choose machine learning models.  

Wang et al. echo previous research, arguing that complete automation might not be desirable in all use cases and highlighting the multifarious objectives of data scientists' work \cite{DakuoCSCW2019}. Their study also revealed the different relationships between human and \automl, such as \automl as a collaborator, teacher and a data scientist. They concluded their paper by outlining design recommendations that allow \automl to augment human data scientists through collaboration, for example, integrating xAI techniques in \automl user interfaces to provide answers in some of the "why" questions to increase trust and giving data scientists the full control over the final choices of the entire pipeline and design these features for model interpretation for users from diverse backgrounds. 

Drozdal et al. studied trust in \automl and found that increasing transparency increases trust, however it depends on the users' purposes and context. \cite{DrozdalTrustAutoml}

\subsection{Empirical Studies of Data Practitioners}
Recent research has also studied data science and machine learning practitioners' workflow without automated machine learning. \cite{}. Amershi et al. surveyed software engineers about their work practices building and integrating machine learning into software and services. They conducted interviews to gather insights that informed their research questions and developed a wide-scale survey about the identified topics. They identified a challenge in machine learning is that iterating on models is time and labor extensive. Another set of related work studied non-experts of machine learning. For example, Yang et al. used interviews and survey and investigated how non-experts build machine learning solutions in real life. \cite{YangNonExpert} Kandel et al. studied analysts in the industry to understand their work process, struggles and potential solutions. \cite{Kandel}

To our knowledge, no research has drawn all their study subjects from users of automated machine learning who have experience using \automl in real-world applications and with an established relationship with \automl tools. Many existing studies focus only on the modelling phase in the machine learning process. Our study contributes to existing work by studying users who have used \automl for real-world applications and we sought to understand their work practices across all stages of the machine learning process and the humans involvement in their current workflow. 
Our study answers the following questions:[TODO: add more details depending on the findings]
\textbf{RQ1}: Who are the users of Automated Machine Learning tools?
\textbf{RQ2}: What are their current work practices and what strategies do they employ to integrate automated machine learning into their existing workflow?
\textbf{RQ3}: What are their perceptions of \automl and what are the affect of \automl on \automl users?


% \subsection{Our Contribution to Prior Work}
% Prior work has leveraged controlled experiments or have studied machine learning practitioners. 


% We reveal the multifarious motivations of the practicing machine learning: enjoyment (similar to readings in 203 about professional values of nurses who want to provide care.) or not to simply gain the best accuracy score [is there anything besides what's covered in Dakuo's uncover relationship in the data?] [This begs the question, what do data scientists use machine learning for?]









